"""
Tests for the RAG System module.
"""
import pytest
from unittest.mock import Mock, patch, MagicMock
import os
import sys

# Add src directory to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from rag_system import RAGSystem


class TestRAGSystem:
    """Test cases for RAG System functionality."""
    
    @patch.dict(os.environ, {
        'AZURE_SEARCH_NAME': 'test-search-service',
        'AZURE_SEARCH_KEY': 'test-key',
        'AZURE_SEARCH_INDEX': 'test-index',
        'AZURE_OPENAI_ENDPOINT': 'https://test.openai.azure.com/',
        'AZURE_OPENAI_KEY': 'test-openai-key',
        'AZURE_OPENAI_DEPLOYMENT': 'test-gpt-deployment',
        'AZURE_OPENAI_EMBEDDING_DEPLOYMENT': 'test-embedding-deployment'
    })
    @patch('rag_system.SearchClient')
    @patch('rag_system.AzureOpenAI')
    @patch('rag_system.AzureChatOpenAI')
    def test_rag_system_initialization(self, mock_azure_chat, mock_azure_openai, mock_search_client):
        """Test that RAG system initializes correctly with environment variables."""
        
        # Mock the clients
        mock_search_client.return_value = Mock()
        mock_azure_openai.return_value = Mock()
        mock_azure_chat.return_value = Mock()
        
        # Initialize RAG system
        rag_system = RAGSystem()
        
        # Verify initialization
        assert rag_system is not None
        assert hasattr(rag_system, 'search_client')
        assert hasattr(rag_system, 'openai_client')
        assert hasattr(rag_system, 'llm')
        assert rag_system.index_name == 'test-index'
        
        # Verify that clients were called with correct parameters
        mock_search_client.assert_called_once()
        mock_azure_openai.assert_called_once()
        mock_azure_chat.assert_called_once()
    
    @patch.dict(os.environ, {
        'AZURE_SEARCH_NAME': 'test-search-service',
        'AZURE_SEARCH_KEY': 'test-key',
        'AZURE_SEARCH_INDEX': 'test-index',
        'AZURE_OPENAI_ENDPOINT': 'https://test.openai.azure.com/',
        'AZURE_OPENAI_KEY': 'test-openai-key',
        'AZURE_OPENAI_DEPLOYMENT': 'test-gpt-deployment',
        'AZURE_OPENAI_EMBEDDING_DEPLOYMENT': 'test-embedding-deployment'
    })
    @patch('rag_system.SearchClient')
    @patch('rag_system.AzureOpenAI')
    @patch('rag_system.AzureChatOpenAI')
    def test_ask_method_returns_expected_structure(self, mock_azure_chat, mock_azure_openai, mock_search_client):
        """Test that the ask method returns the expected response structure."""
        
        # Setup mocks
        mock_search_instance = Mock()
        mock_openai_instance = Mock()
        mock_chat_instance = Mock()
        
        mock_search_client.return_value = mock_search_instance
        mock_azure_openai.return_value = mock_openai_instance
        mock_azure_chat.return_value = mock_chat_instance
        
        # Mock embedding response
        mock_embedding_response = Mock()
        mock_embedding_response.data = [Mock()]
        mock_embedding_response.data[0].embedding = [0.1, 0.2, 0.3] * 256  # Mock 768-dim vector
        mock_openai_instance.embeddings.create.return_value = mock_embedding_response
        
        # Mock search results
        mock_doc1 = {
            'content': 'This is test document content about artificial intelligence.',
            'id': 'doc1',
            '@search.score': 0.95
        }
        mock_doc2 = {
            'content': 'Another test document with relevant information.',
            'id': 'doc2', 
            '@search.score': 0.87
        }
        mock_search_instance.search.return_value = [mock_doc1, mock_doc2]
        
        # Mock LLM response
        mock_llm_response = Mock()
        mock_llm_response.content = "This is a test answer generated by the LLM."
        mock_chat_instance.invoke.return_value = mock_llm_response
        
        # Initialize RAG system and test ask method
        rag_system = RAGSystem()
        test_query = "What is artificial intelligence?"
        result = rag_system.ask(test_query)
        
        # Verify response structure
        assert isinstance(result, dict)
        assert 'question' in result
        assert 'answer' in result
        assert 'sources' in result
        assert 'source_count' in result
        
        # Verify response content
        assert result['question'] == test_query
        assert result['answer'] == "This is a test answer generated by the LLM."
        assert len(result['sources']) == 2
        assert result['source_count'] == 2
        
        # Verify sources structure
        source1 = result['sources'][0]
        assert 'content' in source1
        assert 'id' in source1
        assert 'score' in source1
        assert source1['id'] == 'doc1'
        assert source1['score'] == 0.95
        
        # Verify that the embedding and search were called
        mock_openai_instance.embeddings.create.assert_called_once()
        mock_search_instance.search.assert_called_once()
        mock_chat_instance.invoke.assert_called_once()


if __name__ == '__main__':
    pytest.main([__file__])
